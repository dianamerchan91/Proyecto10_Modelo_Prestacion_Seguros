{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning para predecir prestaciones de seguro en la compañía Sure Tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objetivos\" data-toc-modified-id=\"Objetivos-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Objetivos</a></span></li></ul></li><li><span><a href=\"#Preprocesamiento-y-exploración-de-datos\" data-toc-modified-id=\"Preprocesamiento-y-exploración-de-datos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Preprocesamiento y exploración de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inicialización\" data-toc-modified-id=\"Inicialización-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Inicialización</a></span></li><li><span><a href=\"#Carga-de-datos\" data-toc-modified-id=\"Carga-de-datos-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Carga de datos</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Análisis-exploratorio-de-datos\" data-toc-modified-id=\"Análisis-exploratorio-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Análisis exploratorio de datos</a></span></li><li><span><a href=\"#Tarea-1.-Clientes-similares\" data-toc-modified-id=\"Tarea-1.-Clientes-similares-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Tarea 1. Clientes similares</a></span></li><li><span><a href=\"#Tarea-2.-¿Es-probable-que-el-cliente-reciba-una-prestación-del-seguro?\" data-toc-modified-id=\"Tarea-2.-¿Es-probable-que-el-cliente-reciba-una-prestación-del-seguro?-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Tarea 2. ¿Es probable que el cliente reciba una prestación del seguro?</a></span></li><li><span><a href=\"#Tarea-3.-Regresión-(con-regresión-lineal)\" data-toc-modified-id=\"Tarea-3.-Regresión-(con-regresión-lineal)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Tarea 3. Regresión (con regresión lineal)</a></span></li><li><span><a href=\"#Tarea-4.-Ofuscar-datos\" data-toc-modified-id=\"Tarea-4.-Ofuscar-datos-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Tarea 4. Ofuscar datos</a></span></li><li><span><a href=\"#Prueba-de-que-la-ofuscación-de-datos-puede-funcionar-con-regresión-lineal\" data-toc-modified-id=\"Prueba-de-que-la-ofuscación-de-datos-puede-funcionar-con-regresión-lineal-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Prueba de que la ofuscación de datos puede funcionar con regresión lineal</a></span></li><li><span><a href=\"#Prueba-de-regresión-lineal-con-ofuscación-de-datos\" data-toc-modified-id=\"Prueba-de-regresión-lineal-con-ofuscación-de-datos-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Prueba de regresión lineal con ofuscación de datos</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusiones</a></span></li><li><span><a href=\"#Apéndices\" data-toc-modified-id=\"Apéndices-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Apéndices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Apéndice-A:-Escribir-fórmulas-en-los-cuadernos-de-Jupyter\" data-toc-modified-id=\"Apéndice-A:-Escribir-fórmulas-en-los-cuadernos-de-Jupyter-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Apéndice A: Escribir fórmulas en los cuadernos de Jupyter</a></span></li><li><span><a href=\"#Apéndice-B:-Propiedades-de-las-matrices\" data-toc-modified-id=\"Apéndice-B:-Propiedades-de-las-matrices-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Apéndice B: Propiedades de las matrices</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "La compañía de seguros Sure Tomorrow está buscando una mejora en la asignación de seguros a sus clientes, por lo que ha decidido recurrir al uso de modelos de machine learning, que le permitan mejorar sus servicios. Los modelos predictivos se han empezado a utilizar dentro del sector de aseguradoras, sobretodo ayudando en la búsqueda de patrones de comportamiento de usuarios, estableciendo la probabilidad de que un nuevo cliente reciba un seguro o en la protección de la información personal de cada cliente. Así que el uso de esta tecnología se está convirtiendo en una herramienta sustancial para la optimización en el trabajo de aseguradoras. \n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. Encontrar clientes que sean similares a un cliente determinado. Esto ayudará a los agentes de la compañía con el marketing.\n",
    "2. Predecir la probabilidad de que un nuevo cliente reciba una prestación del seguro. ¿Puede un modelo de predictivo funcionar mejor que un modelo dummy?\n",
    "3. Predecir el número de prestaciones de seguro que un nuevo cliente pueda recibir utilizando un modelo de regresión lineal.\n",
    "4. Proteger los datos personales de los clientes sin afectar al modelo del ejercicio anterior. Es necesario desarrollar un algoritmo de transformación de datos que dificulte la recuperación de la información personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento u ofuscación de datos. Pero los datos deben protegerse de tal manera que no se vea afectada la calidad de los modelos de machine learning. No es necesario elegir el mejor modelo, basta con demostrar que el algoritmo funciona correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y exploración de datos\n",
    "\n",
    "### Inicialización\n",
    "\n",
    "Iniciamos importando las librerías necesarias para la lectura correcta de archivos, manejo de matrices, desarrollo de gráficos, análisis de datos y construcció de modelos de machine learning. Para este proyecto trabajaremos con las librerías: `Numpy`, `Pandas`, `Scikit-Learn` y `Seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (0.24.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.21.1)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'INSTALLER'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos y hacemos una revisión básica para comprobar que no hay problemas obvios. Guardaremos nuestro dataset como `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos las columnas para que el código se vea más coherente con su estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', \n",
    "                        'Age': 'age', \n",
    "                        'Salary': 'income', \n",
    "                        'Family members': 'family_members', \n",
    "                        'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamaremos al atributo `shape`, a la función `sample` para obtener una muestra aleatoria de 10 filas u observaciones de nuestro dataset. También llamaremos al método `info` e `isna` para analizar los tipos de datos con los que trabajaremos y comprobar la presencia de valores ausentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46200.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>34100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>60300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age   income  family_members  insurance_benefits\n",
       "764        1  30.0  42100.0               2                   0\n",
       "3630       1  24.0  46200.0               3                   0\n",
       "1074       1  29.0  32800.0               1                   0\n",
       "4116       0  35.0  41600.0               4                   0\n",
       "1976       1  45.0  32300.0               2                   1\n",
       "3364       1  21.0  24300.0               1                   0\n",
       "693        1  39.0  34100.0               1                   0\n",
       "2867       1  32.0  48900.0               0                   0\n",
       "4423       1  27.0  46300.0               0                   0\n",
       "2278       0  49.0  60300.0               1                   2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              5000 non-null   int64  \n",
      " 1   age                 5000 non-null   float64\n",
      " 2   income              5000 non-null   float64\n",
      " 3   family_members      5000 non-null   int64  \n",
      " 4   insurance_benefits  5000 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                0\n",
       "age                   0\n",
       "income                0\n",
       "family_members        0\n",
       "insurance_benefits    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataset cuenta con 5000 filas y 5 columnas. Las columnas `gender`, `age`, `income` y `family_members` corresponden a las características de nuestro modelo predictivo, mientras que la `insurance_benefits` a nuestro objetivo. En cada columna se observar la siguiente información:\n",
    "\n",
    "- `gender`: género del cliente (0 Masculino, 1 Femenino)\n",
    "- `age`: edad del cliente\n",
    "- `income`: ingresos del cliente\n",
    "- `family_members`: número de miembros en la familia\n",
    "- `insurance_benefits`: cantidad de beneficios de seguro recibido por el cliente\n",
    "\n",
    "No se registran valores ausentes en nuestro dataset, pero será necesario transformar el tipo de dato de la columna edad de float a int, para esto utilizaremos la función astype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos el tipo de dato a entero en la columna age\n",
    "df['age'] = df['age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              5000 non-null   int64  \n",
      " 1   age                 5000 non-null   int64  \n",
      " 2   income              5000 non-null   float64\n",
      " 3   family_members      5000 non-null   int64  \n",
      " 4   insurance_benefits  5000 non-null   int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos que la conversión se haya realizado con éxito\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corregido el tipo de datos vamos a echar un vistazo a las estadísticas descriptivas de los datos, para esto llamaremos al método describe() y también estableceremos el recuento de valores únicos para las columnas `gender`, `family_members` e `insurance_benefits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499000</td>\n",
       "      <td>30.952800</td>\n",
       "      <td>39916.360000</td>\n",
       "      <td>1.194200</td>\n",
       "      <td>0.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500049</td>\n",
       "      <td>8.440807</td>\n",
       "      <td>9900.083569</td>\n",
       "      <td>1.091387</td>\n",
       "      <td>0.463183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>33300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>40200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>46600.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>79000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          age        income  family_members  \\\n",
       "count  5000.000000  5000.000000   5000.000000     5000.000000   \n",
       "mean      0.499000    30.952800  39916.360000        1.194200   \n",
       "std       0.500049     8.440807   9900.083569        1.091387   \n",
       "min       0.000000    18.000000   5300.000000        0.000000   \n",
       "25%       0.000000    24.000000  33300.000000        0.000000   \n",
       "50%       0.000000    30.000000  40200.000000        1.000000   \n",
       "75%       1.000000    37.000000  46600.000000        2.000000   \n",
       "max       1.000000    65.000000  79000.000000        6.000000   \n",
       "\n",
       "       insurance_benefits  \n",
       "count         5000.000000  \n",
       "mean             0.148000  \n",
       "std              0.463183  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              5.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.501\n",
      "1    0.499\n",
      "Name: gender, dtype: float64\n",
      "1    0.3628\n",
      "0    0.3026\n",
      "2    0.2142\n",
      "3    0.0878\n",
      "4    0.0248\n",
      "5    0.0064\n",
      "6    0.0014\n",
      "Name: family_members, dtype: float64\n",
      "0    0.8872\n",
      "1    0.0846\n",
      "2    0.0230\n",
      "3    0.0036\n",
      "4    0.0014\n",
      "5    0.0002\n",
      "Name: insurance_benefits, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_categorical = df[['gender', 'family_members', 'insurance_benefits']]\n",
    "\n",
    "for col in df_categorical:\n",
    "    print(df_categorical[col].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de la edad `age`, los clientes de Sure Tomorrow presentan una edad promedio de alrededor de 30 años, siendo la edad más alta registrada 65 años. La diferencia entre la media y la mediana es de 0.95, y nos indica un mínimo sesgo hacia la derecha en la distribución de las edades. En cuanto al género `gender`, existe un mayor porcentaje de clientes del género masculino, alrededor del 50% y un menor porcentaje de mujeres, con un 49%. \n",
    "\n",
    "El ingreso promedio `income` registrado fue de 39916 dólares, con un valor mínimo de 5300 y un máximo de 79000. Este valor máximo es mayor a la suma del promedio más tres desviaciones estándar, por lo que se puede establecer la presencia de valores atípicos en esta columna. La media es inferior a la mediana, lo que nos indica una asimetría negativa de nuestros datos, con un mayor número de datos por debajo de la media.\n",
    "\n",
    "En cuanto al número de miembros de familia `family_members`, nos encontramos con un promedio de alrededor de 1, el valor mínimo es de 0 y el máximo de 6. Se puede observar que el valor para Q1 (cuantil 1) es cero, mientras que para el Q3 (cuantil 3) es dos, por lo que la mayoría de nuestros datos se distribuirán dentro de este rango. A su vez, esto se corrobora al estudiar los recuentos de valores únicos, dónde familias conformadas por cero a dos miembros, son las que representan el 84% de clientes. Mientras que clientes de familias con más de tres miembros constituyen un porcentaje menor. \n",
    "\n",
    "En el caso del número de beneficios `insurance_benefits`, se puede observar que la mayoría de clientes no han recibido un beneficio de seguro, ya que tanto el promedio, mediana, Q1 y Q3, se mantienen en valores de cero. Esto se puede comprobar al analizar los valores únicos de esta columna, pudiendo observar que el 88% de clientes no poseen una prestación de seguro. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "1. Al realizar una revisión básica de nuestros datos, no se registraron valores ausentes. \n",
    "2. Se decidió renombrar a las columnas del dataset para mantener un estilo coherente. \n",
    "3. El tipo de dato de la columna `age` se presentaba como tipo float por lo que se realizó su cambio a tipo entero. \n",
    "4. Se realizó un análisis de las estadísticas descriptivas y se encontró que el promedio de edad de los clientes es 30 años, con un mayor porcentaje de hombres que mujeres. Por otro lado, la mayoría de clientes presentan entre 0 a 2 miembros en sus familias, representando cerca del 84% de usuarios. \n",
    "5. Finalmente, el 88% de clientes no han recibido una prestación de seguro. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar rápidamente si existen determinados grupos de clientes observando el gráfico de pares. También trazaremos un gráfico `heatmap` para poder esclarecer cómo se correlacionan las diferentes características de nuestros datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES PRINCIPALES**\n",
    "\n",
    "- Al analizar el gráfico de pares, podemos observar los histogramas de frecuencia para cada columna, ubicados en la diagonal del gráfico, dónde se comprueba el alto número de clientes que no han recibido una prestación de seguro. A su vez, se observa cómo familias con 0 a 2 miembros son las que representan el porcentaje más alto de usuarios. Por otro lado, se verifica la asimetría negativa de los ingresos y una asimetría positiva para la edad, con un mayor número de clientes entre los 18 a 40 años. \n",
    "- `gender`: En el caso de la variable género, no observamos la formación de grupos obvios con otras variables. Esto se confirma con la baja correlación existente entre ambas variables (0.01). Se podría indicar que, para el género 1 o femenino, se registran hasta cinco prestaciones de seguros, mientras que para los hombres no se registra esto. \n",
    "- `age`: En el caso de los ingresos, se puede observar ingresos más altos para clientes de menor edad, pero no hay una agrupación clara de los datos, además de que la correlación negativa es cercana a cero (-0.019). Por otro lado, al analizar la relación entre el número de miembros por familia y la edad, nos encontramos con una correlación baja (-0.0067), y se podría distinguir una tendencia a que mientras más años tenga el cliente, más pequeña será la familia a la que pertenece. Finalmente, la correlación positiva más alta (0.65) se registra entre la edad y el número de prestaciones de seguro, es así que clientes jóvenes reciben menos prestaciones, que aquellos clientes por encima de los 40 años. A mayor edad, es más probable que reciba más beneficios de seguros. \n",
    "- `income`: para el caso de los ingresos no se observan grupos que determinen un patrón específico, además de que las correlaciones son cercanas a cero. \n",
    "- `family_members`: observando el gráfico de pares, se hace evidente que familias más pequeñas de hasta dos miembros, pueden llegar a recibir un mayor número de beneficios de seguro, mientras que para familias más grandes es poco frecuente que reciban más de dos prestaciones. \n",
    "\n",
    "Finalmente, podemos concluir que es un poco complicado detectar grupos obvios (clústeres) ya que es difícil combinar diversas variables simultáneamente (para analizar distribuciones multivariadas). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 1. Clientes similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos más cercanos (objetos) para un objeto dado basándose en la distancia entre los objetos. Partiendo de esta premisa, estableceremos aquellos clientes más similares en base a las características `gender`, `age`, `income` y `family_members` a través del uso de la distancia Euclideana y la distancia Manhattan, tanto para datos escalados como no escalados. \n",
    "\n",
    "Escribiremos la función `get_knn` que devolverá los k vecinos más cercanos para un $n^{th}$ objeto basándose en una métrica de distancia especificada. Para esto consideraremos las características y distancias previamente planteadas, no se considerará el número de prestaciones de seguro recibidas.\n",
    "\n",
    "Utilizaremos la implementación ya existente del algoritmo kNN `NearestNeighbors` de scikit-learn ([el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)). Probaremos la función para cuatro combinaciones de dos casos:\n",
    "\n",
    "- Escalado\n",
    "  - los datos no están escalados\n",
    "  - los datos se escalan con el escalador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html)\n",
    "  \n",
    "- Métricas de distancia\n",
    "  - Euclidiana\n",
    "  - Manhattan\n",
    "\n",
    "Finalmente se responderá las siguientes preguntas\n",
    "\n",
    "- ¿El hecho de que los datos no estén escalados afecta al algoritmo kNN? Si es así, ¿cómo se manifiesta?\n",
    "- ¿Qué tan similares son los resultados al utilizar la métrica de distancia Manhattan (independientemente del escalado)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las características necesarias para establecer kNN\n",
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Devuelve los k vecinos más cercanos\n",
    "\n",
    "    :param df: DataFrame de pandas utilizado para encontrar objetos similares dentro del mismo lugar    \n",
    "    :param n: número de objetos para los que se buscan los vecinos más cercanos    \n",
    "    :param k: número de vecinos más cercanos a devolver\n",
    "    :param métrica: nombre de la métrica de distancia    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Establecemos nuestro modelo de vecinos más cercanos y lo entrenamos con las características establecidas\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nbrs.fit(df[feature_names].values)\n",
    "    \n",
    "    # Obtenemos las distancias e índices de n número de objetos \n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    # Creamos un dataframe que nos devolverá los vecinos más cercanos para un determinado objeto\n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos los datos y los guardamos como `df_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.321519</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.443038</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.687342</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits\n",
       "999      0.0  0.415385  0.321519        0.333333                   0\n",
       "4287     1.0  0.369231  0.468354        0.333333                   0\n",
       "2119     1.0  0.369231  0.559494        0.166667                   0\n",
       "2740     0.0  0.523077  0.443038        0.166667                   0\n",
       "227      0.0  0.430769  0.687342        0.166667                   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a obtener registros similares para el objeto 250 del dataset, para cada combinación.\n",
    "\n",
    "**DISTANCIA EUCLIDEANA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.236068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.582576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.082763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.403124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.124038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.071247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age   income  family_members  insurance_benefits   distance\n",
       "250        0   26  44700.0               2                   0   0.000000\n",
       "3682       0   28  44700.0               3                   0   2.236068\n",
       "172        1   22  44700.0               2                   0   4.123106\n",
       "4523       0   22  44700.0               0                   0   4.472136\n",
       "1224       1   22  44700.0               0                   0   4.582576\n",
       "927        1   21  44700.0               1                   0   5.196152\n",
       "2350       0   20  44700.0               1                   0   6.082763\n",
       "432        1   32  44700.0               4                   0   6.403124\n",
       "3913       1   34  44700.0               3                   0   8.124038\n",
       "370        1   40  44700.0               1                   0  14.071247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_euclidean = get_knn(df, 250, 10, 'euclidean')\n",
    "df_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.564557</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.558228</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.564557</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.548101</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.579747</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.589873</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits  distance\n",
       "250      0.0  0.400000  0.565823        0.333333                   0  0.000000\n",
       "4013     0.0  0.400000  0.564557        0.333333                   0  0.001266\n",
       "1354     0.0  0.400000  0.558228        0.333333                   0  0.007595\n",
       "932      0.0  0.400000  0.556962        0.333333                   0  0.008861\n",
       "881      0.0  0.384615  0.564557        0.333333                   0  0.015437\n",
       "1064     0.0  0.415385  0.562025        0.333333                   0  0.015846\n",
       "4152     0.0  0.400000  0.548101        0.333333                   0  0.017722\n",
       "4335     0.0  0.384615  0.579747        0.333333                   0  0.020750\n",
       "2686     0.0  0.400000  0.589873        0.333333                   0  0.024051\n",
       "574      0.0  0.415385  0.546835        0.333333                   0  0.024438"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled_euclidean = get_knn(df_scaled, 250, 10, 'euclidean')\n",
    "df_scaled_euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISTANCIA MANHATTAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>44700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age   income  family_members  insurance_benefits  distance\n",
       "250        0   26  44700.0               2                   0       0.0\n",
       "3682       0   28  44700.0               3                   0       3.0\n",
       "172        1   22  44700.0               2                   0       5.0\n",
       "4523       0   22  44700.0               0                   0       6.0\n",
       "2350       0   20  44700.0               1                   0       7.0\n",
       "927        1   21  44700.0               1                   0       7.0\n",
       "1224       1   22  44700.0               0                   0       7.0\n",
       "432        1   32  44700.0               4                   0       9.0\n",
       "3913       1   34  44700.0               3                   0      10.0\n",
       "370        1   40  44700.0               1                   0      16.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_manhattan = get_knn(df, 250, 10, 'cityblock')\n",
    "df_manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.565823</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.564557</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.558228</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.564557</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.548101</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.589873</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.579747</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits  distance\n",
       "250      0.0  0.400000  0.565823        0.333333                   0  0.000000\n",
       "4013     0.0  0.400000  0.564557        0.333333                   0  0.001266\n",
       "1354     0.0  0.400000  0.558228        0.333333                   0  0.007595\n",
       "932      0.0  0.400000  0.556962        0.333333                   0  0.008861\n",
       "881      0.0  0.384615  0.564557        0.333333                   0  0.016650\n",
       "4152     0.0  0.400000  0.548101        0.333333                   0  0.017722\n",
       "1064     0.0  0.415385  0.562025        0.333333                   0  0.019182\n",
       "2686     0.0  0.400000  0.589873        0.333333                   0  0.024051\n",
       "4335     0.0  0.384615  0.579747        0.333333                   0  0.029309\n",
       "4482     0.0  0.400000  0.597468        0.333333                   0  0.031646"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled_manhattan = get_knn(df_scaled, 250, 10, 'cityblock')\n",
    "df_scaled_manhattan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos un dataframe con la lista de índices de clientes más similares al cliente 250, para poder establecer las diferencias entre las dos distancias utilizadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_euclidean</th>\n",
       "      <th>df_manhattan</th>\n",
       "      <th>df_scaled_euclidean</th>\n",
       "      <th>df_scaled_manhattan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3682</td>\n",
       "      <td>3682</td>\n",
       "      <td>4013</td>\n",
       "      <td>4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>1354</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4523</td>\n",
       "      <td>4523</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1224</td>\n",
       "      <td>2350</td>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>1064</td>\n",
       "      <td>4152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2350</td>\n",
       "      <td>1224</td>\n",
       "      <td>4152</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>4335</td>\n",
       "      <td>2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3913</td>\n",
       "      <td>3913</td>\n",
       "      <td>2686</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>574</td>\n",
       "      <td>4482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_euclidean  df_manhattan  df_scaled_euclidean  df_scaled_manhattan\n",
       "0           250           250                  250                  250\n",
       "1          3682          3682                 4013                 4013\n",
       "2           172           172                 1354                 1354\n",
       "3          4523          4523                  932                  932\n",
       "4          1224          2350                  881                  881\n",
       "5           927           927                 1064                 4152\n",
       "6          2350          1224                 4152                 1064\n",
       "7           432           432                 4335                 2686\n",
       "8          3913          3913                 2686                 4335\n",
       "9           370           370                  574                 4482"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_index = pd.DataFrame({\n",
    "    'df_euclidean': df_euclidean.index,\n",
    "    'df_manhattan': df_manhattan.index,\n",
    "    'df_scaled_euclidean': df_scaled_euclidean.index,\n",
    "    'df_scaled_manhattan': df_scaled_manhattan.index   \n",
    "})\n",
    "\n",
    "list_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respondemos a las preguntas planteadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿El hecho de que los datos no estén escalados afecta al algoritmo kNN? Si es así, ¿cómo se manifiesta?** \n",
    "\n",
    "El hecho de que los datos no estén escalados evidentemente afecta al algoritmo kNN, esto se manifiesta a través de distancias más grandes para el conjunto de datos no escalado, mientras que al escalar, las distancias son más cortas. Esto se debe a que al no realizar una estandarización, se realiza una ponderación exagerada y ciertas características como la edad o el ingreso van a tener un mayor peso al presentar valores más altos, de hasta 65 en edad y 79000 en ingresos. \n",
    "\n",
    "También se puede observar cambios en la lista de clientes más similares al objeto establecido. Estos son idénticos para ambas distancias sin escalar, mientras que al no escalar los datos, obtenemos un grupo de clientes completamente diferente. Por ejemplo, el cliente más similar sin escalar, con índice 3682, presenta tres miembros de familia, lo cual contrasta con el cliente seleccionado 250, que registra solo dos miembros. A su vez, podemos observar clientes de géneros diferentes o con un mayor diferencia de edad. Al estandarizar los datos controlamos estas diferencias en escalas, y por tanto obtenemos una nueva lista de clientes similares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué tan similares son los resultados al utilizar la métrica de distancia Manhattan (independientemente del escalado)?** \n",
    "\n",
    "Si analizamos la lista de índices obtenidos y comparamos los resultados de cada distancia independientemente del escalado, vamos a observar que en el caso de los datos no estandarizados, obtenemos una lista más o menos similar de clientes, con ligeros cambios en el orden o en la distancia que presentan. Por ejemplo, el cliente con índice 1224, es el cuarto más cercano en la distancia euclideana, mientras que para la distancia manhattan este cliente es el sexto más similar. A su vez, al fijarnos solo en nuestros datos estandarizados, nos encontramos con ciertos cambios a partir del cuarto cliente más cercano. Es así que el cliente 4152 es el sexto más cercano en la distancia euclidiana, mientras que es el quinto para la distancia manhattan. También observamos clientes que no comparten ambas listas, como los usuarios 574 y 4482. \n",
    "\n",
    "Pudiendo establecer que los resultados son similares entre ambas métricas, sin embargo se generan algunos cambios debido a que cómo se calcula cada distanca. Para calcular la distancia euclideana utilizamos el valor de la hipotenusa o la distancia más corta entre dos puntos en un plano, mientras que para la distancia manhattan utilizamos la suma de los valores absolutos de catetos. Por lo tanto, la distancia Manhattan siempre presentará valores mayores, ya que la suma de catetos siempre será mayor a la hipotenusa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2. ¿Es probable que el cliente reciba una prestación del seguro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos de machine learning podemos considerarlo este modelo como una tarea de clasificación binaria. Por lo tanto, será necesario transformar el número de beneficios del seguro en característica categórica. Para esto tendremos que transformar las prestaciones máyores a 0 en una sola categoría, en este caso será 1, y posteriormente construir un clasificador basado en kNN, cuya calidad será medida con la métrica F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos estableciendo el valor de `insurance_benefits` superior a cero como objetivo, y evaluaremos si el enfoque de clasificación kNN puede funcionar mejor que el modelo dummy. Realizaremos lo siguiente:\n",
    "\n",
    "- Construiremos un clasificador basado en KNN y mediremos su calidad con la métrica F1 para k=1...10 tanto para los datos originales como para los escalados. Queremos observar cómo k puede influir en la métrica de evaluación y si el escalado de los datos provoca alguna diferencia. Utilizaremos una implementación ya existente del algoritmo de clasificación kNN de scikit-learn ([el enlace](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)).\n",
    "- Construiremos un modelo dummy que, en este caso, es simplemente un modelo aleatorio. Debería devolver \"1\" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestación del seguro, 0.5, 1.\n",
    "\n",
    "La probabilidad de pagar cualquier prestación del seguro puede definirse como:\n",
    "\n",
    "$$\n",
    "P\\{\\text{prestación de seguro recibida}\\}=\\frac{\\text{número de clientes que han recibido alguna prestación de seguro}}{\\text{número total de clientes}}.\n",
    "$$\n",
    "\n",
    "Dividiremos todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporción 70:30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el objetivo \n",
    "df['insurance_benefits_received'] = df['insurance_benefits'].where(df_scaled['insurance_benefits'] == 0, 1)\n",
    "\n",
    "df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits'].where(df_scaled['insurance_benefits'] == 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.8872\n",
       "1    0.1128\n",
       "Name: insurance_benefits_received, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos el desequilibrio de clases para datos sin escalar con value_counts()\n",
    "df['insurance_benefits_received'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.8872\n",
       "1    0.1128\n",
       "Name: insurance_benefits_received, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos el desequilibrio de clases para datos escalados con value_counts()\n",
    "df_scaled['insurance_benefits_received'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto entrenamiento: (3500, 4) (3500,)\n",
      "Tamaño conjunto prueba: (1500, 4) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características y objetivos para el dataset no escalado\n",
    "features = df.drop(['insurance_benefits_received', 'insurance_benefits'], axis=1)\n",
    "target = df['insurance_benefits_received']\n",
    "\n",
    "# Dividimos los datos en un dataset de entrenamiento y prueba (propoción 70:30)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,\n",
    "                                                                             target, \n",
    "                                                                             test_size=0.30,\n",
    "                                                                             random_state=12345)\n",
    "\n",
    "# Comprobamos que la división se realizó correctamente, llamando a shape\n",
    "print('Tamaño conjunto entrenamiento:', features_train.shape, target_train.shape)\n",
    "print('Tamaño conjunto prueba:', features_test.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño conjunto entrenamiento escalado: (3500, 4) (3500,)\n",
      "Tamaño conjunto prueba escalado: (1500, 4) (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características y objetivos para el dataset escalado 'df_scaled'\n",
    "features_scaled = df_scaled.drop(['insurance_benefits_received', 'insurance_benefits'], axis=1)\n",
    "target_scaled = df_scaled['insurance_benefits_received']\n",
    "\n",
    "# Dividimos los datos en un dataset de entrenamiento y prueba (propoción 70:30)\n",
    "features_train_sc, features_test_sc, target_train_sc, target_test_sc = train_test_split(features_scaled,\n",
    "                                                                             target_scaled, \n",
    "                                                                             test_size=0.30,\n",
    "                                                                             random_state=12345)\n",
    "\n",
    "# Comprobamos que la división se realizó correctamente, llamando a shape\n",
    "print('Tamaño conjunto entrenamiento escalado:', features_train_sc.shape, target_train_sc.shape)\n",
    "print('Tamaño conjunto prueba escalado:', features_test_sc.shape, target_test_sc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Devuelve el puntaje F1 y la matriz de confusión a partir de un objetivo y sus predicciones\n",
    "\n",
    "    :param y_true: valores objetivo     \n",
    "    :param y_pred: valores de predicciones obtenidas al entrenar un modelo     \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Llamamos al puntaje F1 del módulo metrics\n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "    # Construimos una matriz de confusión    \n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Matriz de confusión')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la salida de un modelo aleatorio\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "         \n",
    "    \"\"\"\n",
    "    Devuelve la probabilidad de un modelo aleatorio\n",
    "\n",
    "    :param P: probabilidad    \n",
    "    :param size: tamaño del dataset\n",
    "    :param seed: establecemos una semilla para que los resultados sean reproducibles\n",
    "    \n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilidad: 0.00\n",
      "F1: 0.00\n",
      "Matriz de confusión\n",
      "[[0.8872 0.    ]\n",
      " [0.1128 0.    ]]\n",
      "\n",
      "La probabilidad: 0.11\n",
      "F1: 0.12\n",
      "Matriz de confusión\n",
      "[[0.7914 0.0958]\n",
      " [0.0994 0.0134]]\n",
      "\n",
      "La probabilidad: 0.50\n",
      "F1: 0.20\n",
      "Matriz de confusión\n",
      "[[0.456  0.4312]\n",
      " [0.053  0.0598]]\n",
      "\n",
      "La probabilidad: 1.00\n",
      "F1: 0.20\n",
      "Matriz de confusión\n",
      "[[0.     0.8872]\n",
      " [0.     0.1128]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el puntaje F1 y matriz de confusión para cada probabilidad: 0, probabilidad de pagar una prestación, 0.5 y 1 \n",
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'La probabilidad: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, len(df), seed=42)\n",
    "        \n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_neighbors:1\n",
      "F1: 0.61\n",
      "Matriz de confusión\n",
      "[[0.87       0.02133333]\n",
      " [0.052      0.05666667]]\n",
      "\n",
      "K_neighbors:2\n",
      "F1: 0.41\n",
      "Matriz de confusión\n",
      "[[0.88733333 0.004     ]\n",
      " [0.08       0.02866667]]\n",
      "\n",
      "K_neighbors:3\n",
      "F1: 0.41\n",
      "Matriz de confusión\n",
      "[[0.88       0.01133333]\n",
      " [0.078      0.03066667]]\n",
      "\n",
      "K_neighbors:4\n",
      "F1: 0.28\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.09066667 0.018     ]]\n",
      "\n",
      "K_neighbors:5\n",
      "F1: 0.27\n",
      "Matriz de confusión\n",
      "[[0.88533333 0.006     ]\n",
      " [0.09066667 0.018     ]]\n",
      "\n",
      "K_neighbors:6\n",
      "F1: 0.11\n",
      "Matriz de confusión\n",
      "[[0.89       0.00133333]\n",
      " [0.102      0.00666667]]\n",
      "\n",
      "K_neighbors:7\n",
      "F1: 0.11\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.102      0.00666667]]\n",
      "\n",
      "K_neighbors:8\n",
      "F1: 0.07\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.10466667 0.004     ]]\n",
      "\n",
      "K_neighbors:9\n",
      "F1: 0.08\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.104      0.00466667]]\n",
      "\n",
      "K_neighbors:10\n",
      "F1: 0.00\n",
      "Matriz de confusión\n",
      "[[0.89133333 0.        ]\n",
      " [0.10866667 0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construimos un bucle for para obtener el puntaje F1 para el dataset sin escalar\n",
    "for k in range(1, 11):\n",
    "    \n",
    "    neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train, target_train)\n",
    "    predictions = neigh.predict(features_test)\n",
    "    \n",
    "    print(f'K_neighbors:{k}')\n",
    "    eval_classifier(target_test, predictions)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_neighbors:1\n",
      "F1: 0.97\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.00466667 0.104     ]]\n",
      "\n",
      "K_neighbors:2\n",
      "F1: 0.93\n",
      "Matriz de confusión\n",
      "[[8.90666667e-01 6.66666667e-04]\n",
      " [1.40000000e-02 9.46666667e-02]]\n",
      "\n",
      "K_neighbors:3\n",
      "F1: 0.95\n",
      "Matriz de confusión\n",
      "[[0.88933333 0.002     ]\n",
      " [0.00866667 0.1       ]]\n",
      "\n",
      "K_neighbors:4\n",
      "F1: 0.91\n",
      "Matriz de confusión\n",
      "[[0.88933333 0.002     ]\n",
      " [0.01666667 0.092     ]]\n",
      "\n",
      "K_neighbors:5\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88666667 0.00466667]\n",
      " [0.01133333 0.09733333]]\n",
      "\n",
      "K_neighbors:6\n",
      "F1: 0.90\n",
      "Matriz de confusión\n",
      "[[0.89       0.00133333]\n",
      " [0.018      0.09066667]]\n",
      "\n",
      "K_neighbors:7\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88733333 0.004     ]\n",
      " [0.01266667 0.096     ]]\n",
      "\n",
      "K_neighbors:8\n",
      "F1: 0.90\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.01733333 0.09133333]]\n",
      "\n",
      "K_neighbors:9\n",
      "F1: 0.92\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.01466667 0.094     ]]\n",
      "\n",
      "K_neighbors:10\n",
      "F1: 0.88\n",
      "Matriz de confusión\n",
      "[[0.88866667 0.00266667]\n",
      " [0.02133333 0.08733333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construimos un bucle for para obtener el puntaje F1 para el dataset escalado\n",
    "for k in range(1, 11):\n",
    "    \n",
    "    neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(features_train_sc, target_train_sc)\n",
    "    predictions_sc = neigh.predict(features_test_sc)\n",
    "    \n",
    "    print(f'K_neighbors:{k}')\n",
    "    eval_classifier(target_test_sc, predictions_sc)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados obtenidos al construir un modelo de kNN clasificatorio que prediga si un cliente recibirá o no una prestación de seguro, podemos observar que tanto el número de vecinos más cercanos como la estandarización de datos, influyen en las predicciones realizadas. Es así que, para el número de vecino más cercanos, a medida que incrementa este valor, disminuye el puntaje F1, es decir a más vecinos es menor la precisión y sensibilidad de nuestro modelo. Por esto, podemos observar que el puntaje F1 más alto obtenido para los datos estandarizados es de 0.97 pero con un k=1, mientras que para los datos no estandarizados, el puntaje más alto es de 0.61, pero igualmente con un valor k=1. A medida que incrementan los valores de K, el valor F1 disminuye hasta incluso alcanzar un valor de cero, para nuestro dataset no escalado con k=10.\n",
    "\n",
    "Así mismo, se puede observar que la estandarización de datos, es un factor importante que influye en el rendimiento del modelo y por tanto en nuestra métrica F1. Pudiendo determinar que la no estandarización de datos va a disminuir el puntaje F1 de nuestro modelo, alcanzado un valor máximo de 0.61, mientras que al escalar nuestros datos, el puntaje llega hasta 0.97. Esto, como se mencionó anteriormente, estaría relacionado directamente con que los datos no estandarizados, los modelos tienden a dar una mayor importancia a ciertas características que presentan valores más altos, en este caso la edad y los ingresos de cada clientes, estarían influenciado la calidad del modelo. \n",
    "\n",
    "Si consideramos que un modelo aleatorio o dummy que predice que todos los clientes recibirán una prestación de seguro, obtuvo un puntaje F1 de 0.20, mientras que un modelo que predice que ningún cliente recibirá una prestación resultó en un F1 de cero. Podemos establecer que nuestro mejor modelo clasificatorio es aquel de puntaje F1=0.97, k=1 y con datos estandarizados, ya que se encuentra por encima de un modelo constante que predice solo uno. Este modelo es mucho mejor que la aleatoriedad, ya que presenta una proporción más alta de verdaderos positivos y verdaderos negativos, y por otro lado, los falsos positivos y falsos negativos disminuyen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3. Regresión (con regresión lineal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definido nuestro modelo de clasificación binaria, ahora establecermos `insurance_benefits` como nuestro objetivo, y evaluaremos cuál sería la RECM de un modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos nuestra propia implementación de regresión lineal. Para ello, recordaremos cómo está formulada la solución de la tarea de regresión lineal en términos de álgebra lineal. Comprobaremos la RECM tanto para los datos originales como para los escalados, y estableceremos si existe alguna diferencia en la RECM con respecto a estos dos casos.\n",
    "\n",
    "Denotemos- $X$: matriz de características; cada fila es un caso, cada columna es una característica, la primera columna está formada por unidades- $y$ — objetivo (un vector)- $\\hat{y}$ — objetivo estimado (un vector)- $w$ — vector de peso. \n",
    "\n",
    "La tarea de regresión lineal en el lenguaje de las matrices puede formularse así:\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "El objetivo de entrenamiento es entonces encontrar esa $w$ w que minimice la distancia L2 (ECM) entre $Xw$ y $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "Parece que hay una solución analítica para lo anteriormente expuesto:\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "La fórmula anterior puede servir para encontrar los pesos $w$ y estos últimos pueden utilizarse para calcular los valores predichos\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporción 70:30. Utilizaremos la métrica RECM para evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementamos la clase de regresión lineal\n",
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # añadir las unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # calculamos los pesos\n",
    "        self.weights = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # añadir las unidades\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # calculamos los valores predichos\n",
    "        y_pred = np.dot(X2, self.weights)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Devuelve el valor RECM y el coeficiente de determinación R2\n",
    "\n",
    "    :param y_true: valores objetivo   \n",
    "    :param y_pred: valores de predicciones obtenidas al entrenar un modelo \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez implementada nuestra clase MyLinearRegression y creada la función `eval_regressor`, vamos a entrenar nuestro modelo tanto con nuestro dataset original como con nuestro dataset escalado, y evaluaremos las predicciones de cada modelo en base a las métricas RECM y R2.\n",
    "\n",
    "**DATOS ORIGINALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.43539012e-01  3.57495491e-02  1.64272726e-02 -2.60743659e-07\n",
      " -1.16902127e-02]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características X y objetivo y de nuestro dataset original sin escalar\n",
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "# Dividimos en conjuntos de datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "# Establecemos nuestro modelo y lo entrenamos con el conjunto de entrenamiento\n",
    "lr = MyLinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Imprimimos los pesos \n",
    "print(lr.weights)\n",
    "\n",
    "# Realizamos las predicciones en el conjunto de prueba y obtenemos las métricas\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATOS ESCALADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94353901  2.32372069  0.01642727 -0.02059875 -0.07014128]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Establecemos las características X y objetivo y de nuestro dataset escalado\n",
    "X_scaled = df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y_scaled = df_scaled['insurance_benefits'].to_numpy()\n",
    "\n",
    "# Dividimos en conjuntos de datos de entrenamiento y prueba\n",
    "X_train_scal, X_test_scal, y_train_scal, y_test_scal = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=12345)\n",
    "\n",
    "# Establecemos nuestro modelo y lo entrenamos con el conjunto de entrenamiento\n",
    "lr = MyLinearRegression()\n",
    "lr.fit(X_train_scal, y_train_scal)\n",
    "\n",
    "# Imprimimos los pesos \n",
    "print(lr.weights)\n",
    "\n",
    "# Realizamos las predicciones en el conjunto de prueba y obtenemos las métricas\n",
    "y_test_pred_scal = lr.predict(X_test_scal)\n",
    "eval_regressor(y_test_scal, y_test_pred_scal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto para los datos originales como para los datos escalados, obtuvimos los mismos valores para las métrica RECM y R2, que fueron de 0.34 y 0.66 respectivamente. Con esto podemos establecer que el escalamiento de datos no afecta los resultados de métricas en modelos de regresión lineal, por lo que las predicciones realizadas van a ser las mismas entre ambos grupos de datos. A su vez, los resultados de las métricas nos indican que nuestro modelo está trabajando correctamente ya que son valores cercanos a cero. Sin embargo, podemos observar que los valores de pesos obtenidos son diferentes, obteniendo pesos más bajos para los datos no estandarizados, es decir que ciertas características, como edad e ingresos, al no estar escaladas serán más importantes o tendrán un peso exagerado al construir nuestro modelo, lo que explica los cambios en los pesos calculados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 4. Ofuscar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure Tomorrow busca proteger los datos personales de sus clientes, en caso de que caigan en manos equivocadas. Para esto  desarrollaremos un algoritmo de transformación de datos que dificulte la recuperación de la información personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento u ofuscación de datos.\n",
    "\n",
    "Para ofuscar los datos, lo mejor es multiplicar las características numéricas (recuerda que se pueden ver como la matriz $X$) por una matriz invertible $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Comprobaremos cómo quedarán los valores de las características después de la transformación. También la propiedad de invertibilidad es importante aquí, así que nos aseguraremos de que $P$ sea realmente invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>26100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age   income  family_members\n",
       "0       1   41  49600.0               1\n",
       "1       0   46  38000.0               1\n",
       "2       0   29  21000.0               0\n",
       "3       0   21  41700.0               2\n",
       "4       1   28  26100.0               0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecemos las características y filtramos nuestro dataset en base a estas\n",
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]\n",
    "df_pn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 4.10e+01, 4.96e+04, 1.00e+00],\n",
       "       [0.00e+00, 4.60e+01, 3.80e+04, 1.00e+00],\n",
       "       [0.00e+00, 2.90e+01, 2.10e+04, 0.00e+00],\n",
       "       ...,\n",
       "       [0.00e+00, 2.00e+01, 3.39e+04, 2.00e+00],\n",
       "       [1.00e+00, 2.20e+01, 3.27e+04, 3.00e+00],\n",
       "       [1.00e+00, 2.80e+01, 4.06e+04, 1.00e+00]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertimos nuestro dataset en un numpy array\n",
    "X = df_pn.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una matriz aleatoria $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77395605, 0.43887844, 0.85859792, 0.69736803],\n",
       "       [0.09417735, 0.97562235, 0.7611397 , 0.78606431],\n",
       "       [0.12811363, 0.45038594, 0.37079802, 0.92676499],\n",
       "       [0.64386512, 0.82276161, 0.4434142 , 0.22723872]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que la matriz P sea invertible, para esto obtenemos el producto escalar de nuestro matriz P y su matriz inversa. Si el producto escalar es una matriz de identidad o una matriz cuadrada con unos a lo largo de la diagonal principal, entonces podemos establecer que la matriz P es invertible. \n",
    "\n",
    "$$\n",
    "P^{-1}P = PP^{-1} = I\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -1.69848573e-16, -7.58122972e-17,\n",
       "        -1.13112497e-16],\n",
       "       [-6.94895396e-17,  1.00000000e+00, -7.10568689e-17,\n",
       "         3.59096970e-17],\n",
       "       [-1.21269339e-16, -8.01461326e-17,  1.00000000e+00,\n",
       "         4.30764008e-19],\n",
       "       [-3.60694539e-16, -5.55430227e-16,  3.08072404e-16,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_matrix = np.dot(P, np.linalg.inv(P))\n",
    "identity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente obtenemos una matriz de identidad con unos en la diagonal principal, por lo podemos establecer que nuestro matriz P es invertible y nos permitirá ofuscar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos nuestra matriz de ofuscación, para esto obtendremos el producto escalar de $X$ y $P$. Luego intentaremos adivinar la edad o los ingresos de los clientes después de la transformación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6359.71527314, 22380.40467609, 18424.09074184, 46000.69669016],\n",
       "       [ 4873.29406479, 17160.36702982, 14125.78076133, 35253.45577301],\n",
       "       [ 2693.11742928,  9486.397744  ,  7808.83156024, 19484.86063067],\n",
       "       ...,\n",
       "       [ 4346.2234249 , 15289.24126492, 12586.16264392, 31433.50888552],\n",
       "       [ 4194.09324155, 14751.9910242 , 12144.02930637, 30323.88763426],\n",
       "       [ 5205.46827354, 18314.24814446, 15077.01370762, 37649.59295455]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ofus = np.dot(X, P)\n",
    "X_ofus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ofuscados los datos es imposible adivinar la edad o los ingresos de los clientes, ya que obtenemos valores completamente diferentes a los originales. Por lo que podemos decir que nuestro algoritmo de ofuscación funcionará eficazmente para proteger los datos personales de nuestros clientes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora intentaremos recuperar los datos originales de $X'$, a partir de $P$. Esto lo comprobaremos a través de cálculos moviendo $P$ del lado derecho de la fórmula anterior al izquierdo. Aplicaremos las reglas de la multiplicación matricial: \n",
    "\n",
    "$$\n",
    "X = X'\\times P^{-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-4.47363596e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-2.51586878e-12,  2.90000000e+01,  2.10000000e+04,\n",
       "         9.52452315e-13],\n",
       "       ...,\n",
       "       [-1.92837871e-12,  2.00000000e+01,  3.39000000e+04,\n",
       "         2.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.20000000e+01,  3.27000000e+04,\n",
       "         3.00000000e+00],\n",
       "       [ 1.00000000e+00,  2.80000000e+01,  4.06000000e+04,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_recover = np.dot(X_ofus, np.linalg.inv(P))\n",
    "X_recover "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al multiplicar nuestra matriz ofuscada por la matriz inversa $P$, podemos recuperar nuestra matriz original $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora mostraremos los tres casos para algunos clientes:\n",
    "\n",
    "- Datos originales\n",
    "- El que está transformado\n",
    "- El que está invertido (recuperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 4.10e+01, 4.96e+04, 1.00e+00],\n",
       "       [0.00e+00, 4.60e+01, 3.80e+04, 1.00e+00],\n",
       "       [0.00e+00, 2.90e+01, 2.10e+04, 0.00e+00],\n",
       "       [0.00e+00, 2.10e+01, 4.17e+04, 2.00e+00]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6359.71527314, 22380.40467609, 18424.09074184, 46000.69669016],\n",
       "       [ 4873.29406479, 17160.36702982, 14125.78076133, 35253.45577301],\n",
       "       [ 2693.11742928,  9486.397744  ,  7808.83156024, 19484.86063067],\n",
       "       [ 5345.60393712, 18803.22720286, 15479.14837264, 38663.06186284]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ofus[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  4.10000000e+01,  4.96000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-4.47363596e-12,  4.60000000e+01,  3.80000000e+04,\n",
       "         1.00000000e+00],\n",
       "       [-2.51586878e-12,  2.90000000e+01,  2.10000000e+04,\n",
       "         9.52452315e-13],\n",
       "       [-4.84498208e-12,  2.10000000e+01,  4.17000000e+04,\n",
       "         2.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_recover[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar los datos para los cuatro primeros clientes, podemos observar algunos valores diferentes entre nuestra matriz original y nuestra matriz recuperada, estos cambios estarían relacionados en cómo trabaja la librería numpy. Los valores de la matriz ofuscada, obviamente son diferentes, ya que se generan del producto de la matriz original con una matriz aleatoria invertible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de que la ofuscación de datos puede funcionar con regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a demostrar analíticamente que el método de ofuscación no afectará a la regresión lineal en términos de valores predichos, es decir, que sus valores seguirán siendo los mismos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, los datos están ofuscados y ahora tenemos $X \\times P$ en lugar de tener solo $X$. En consecuencia, hay otros pesos $w_P$ como:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cómo se relacionarían $w$ y $w_P$ si simplificáramos la fórmula de $w_P$ anterior?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prueba Analítica**\n",
    "\n",
    "Empezaremos aplicando diferentes propiedades de matrices para simplificar el valor $w_P$ de pesos para la matriz ofuscada.  Recordemos que para ofuscar nuestros datos se multiplicó nuestra matriz original por una matriz invertible $P$:\n",
    "\n",
    "$$\n",
    "w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "Considerando que $(AB)^T = B^TA^T$, entonces:\n",
    "\n",
    "$$\n",
    "w_P = [P^T X^T XP]^{-1} P^T X^T y\n",
    "$$\n",
    "\n",
    "Luego, si $(AB)^{-1} = B^{-1}A^{-1}$:\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} (X^T)^{-1} (P^T)^{-1} P^T X^T y\n",
    "$$\n",
    "\n",
    "De acuerdo a la propiedad de identidad $A^{-1}A = AA^{-1} = I$:\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} (X^T)^{-1} I X^T y\n",
    "$$\n",
    "\n",
    "A su vez, si $IA = AI = A$, entonces:\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} X^{-1} (X^T)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Volviendo a considerar que $(AB)^T = B^TA^T$:\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} (X^TX)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Si tomamos en cuenta que: \n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Podemos concluir que:\n",
    "\n",
    "$$\n",
    "w_P = P^{-1} w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Si simplificamos la fórmula para los pesos $w_P$ a través de las propiedades de matrices establecida en el Apéndice B, podemos establecer que tanto $w_P$ y $w$ se relacionarían a través de la matriz inversa aleatoria P. De esta manera, $w_P$ sería igual al producto de la matriz inversa P y los pesos de la matriz original. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ¿Cuáles serían los valores predichos con $w_P$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prueba Analítica**\n",
    "\n",
    "Una vez simplificada la fórmula para $w_P$, procedemos a  establecer si las predicciones realizadas a partir de la matriz de ofuscación son similares a las realizadas con la matriz original. Empecemos recordando que las predicciones se calculan de la siguiente manera: \n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$\n",
    "\n",
    "Al utilizar nuestra matriz ofuscada, ya no trabajamos solo con $X$ sino con $X x P$, entonces las predicciones serían: \n",
    "\n",
    "$$\n",
    "\\hat{y}_P = X_{val}Pw_P\n",
    "$$\n",
    "\n",
    "Considerando que $w_P = P^{-1} w$, entonces:\n",
    "\n",
    "$$\n",
    "\\hat{y}_P = X_{val}PP^{-1} w\n",
    "$$\n",
    "\n",
    "Tomando en cuenta que $A^{-1}A = AA^{-1} = I$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_P = X_{val}I w\n",
    "$$\n",
    "\n",
    "Si $IA = AI = A$, entonces:\n",
    "\n",
    "$$\n",
    "\\hat{y}_P = X_{val} w\n",
    "$$\n",
    "\n",
    "Si $\\hat{y} = X_{val}w$, podemos concluir que:\n",
    "\n",
    "$$\n",
    "\\hat{y}_P = \\hat{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Como se puede observar al realizar la prueba analítica para los valores predichos con $w_P$, podemos establecer que las predicciones realizadas a partir de una matriz ofuscada van a ser similares a las predicciones realizadas con la matriz original. Concluyendo que analíticamente el ofuscamiento de datos no va a afectará el rendimiento del modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Qué significa esto para la calidad de la regresión lineal si esta se mide mediante la RECM?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta**\n",
    "\n",
    "Si analíticamente, las predicciones obtenidas a partir de una matriz ofuscada son similares a las que se obtienen de la matriz original, entonces podemos establecer que la calidad el modelo no se va a ver afectada, y los resultados de métricas RECM van a ser similares. Pudiendo concluir que el ofuscamiento de datos no alterará la calida de nuestro modelo de regresión lineal y las predicciones serán las mismas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de regresión lineal con ofuscación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, probaremos que la regresión lineal pueda funcionar, en términos computacionales, con la transformación de ofuscación elegida. Utilizando nuestra propia implementación de clase `MyLinearRegression`, ejecutaremos la regresión lineal opcionalmente con la ofuscación.\n",
    "\n",
    "Ejecutaremos la regresión lineal para los datos originales y los ofuscados, compararemos los valores predichos y los valores de las métricas RMSE y $R^2$, y encontraremos diferencias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creamos una matriz cuadrada $P$ de números aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77395605, 0.43887844, 0.85859792, 0.69736803],\n",
       "       [0.09417735, 0.97562235, 0.7611397 , 0.78606431],\n",
       "       [0.12811363, 0.45038594, 0.37079802, 0.92676499],\n",
       "       [0.64386512, 0.82276161, 0.4434142 , 0.22723872]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comprobamos que sea invertible, obteniendo el producto de $P$ con su matriz inversa $P^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -1.69848573e-16, -7.58122972e-17,\n",
       "        -1.13112497e-16],\n",
       "       [-6.94895396e-17,  1.00000000e+00, -7.10568689e-17,\n",
       "         3.59096970e-17],\n",
       "       [-1.21269339e-16, -8.01461326e-17,  1.00000000e+00,\n",
       "         4.30764008e-19],\n",
       "       [-3.60694539e-16, -5.55430227e-16,  3.08072404e-16,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_matrix = np.dot(P, np.linalg.inv(P))\n",
    "identity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nuestra matriz P es invertible ya que obtenemos una matriz de identidad al multiplicarla por su inversa. Ahora, utilizaremos la matriz ofuscada $XP$ como la nueva matriz de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos las características y objetivo \n",
    "X = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "# Creamos nuestra matriz ofuscada 'X_obfuscated'\n",
    "X_obfuscated = np.dot(X, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaremos nuestro modelo de regresión lineal para nuestros datos originales y compararemos los resultados obtenidos, tanto para la métrica RECM y R2, con nuestros datos ofuscados. De esta manera, comprobaremos si nuestra prueba analítica fue correcta. \n",
    "\n",
    "**DATOS ORIGINALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.43539012e-01  3.57495491e-02  1.64272726e-02 -2.60743659e-07\n",
      " -1.16902127e-02]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATOS OFUSCADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.943539   -0.02212237 -0.04451118  0.09522181 -0.01340894]\n",
      "RMSE: 0.34\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_obfuscated, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba computacionalmente, lo que anteriormente se realizó analíticamente, las predicciones realizadas a partir de una matriz ofuscada van a ser similares a las de la matriz original, por tanto los valores de las métricas RECM y R2 son similares. A su vez, nuestro algoritmo de ofuscación de datos trabaja correctamente, protegiendo la información personal de clientes y manteniendo la calidad del modelo de regresión lineal, que mantuvo un RECM=0.34 y un R2=0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. El algoritmo kNN para establecer clientes similares a un cliente determinado funcionó mejor con datos escalados, obteniendo distancias más cortas; ya que al estandarizar los datos, ninguna de las características tiene una ponderación exagerada sino que todas influyen de igual manera al medir distancias. A su vez, se obtuvieron listas similares de clientes tanto con la distancia Euclideana como con la distancia Manhattan, por lo que se podría utilizar cualquiera de estas dos alternativas para determinar la distancia entre vecinos cercanos. Las diferencias registradas entre ambas distancias, estarían relacionadas a la forma en que se calcula cada una de ellas, ya que la distancia Euclideana considera el valor de hipotenusa para su cálculo, mientras que la distancia Manhattan considera la suma de los catetos, por lo tanto este última tiende a ser mayor.  \n",
    "2. Al construir un modelo de clasificación binaria para predecir si un cliente recibirá o no una prestación de seguro, el mejor modelo fue aquel realizado con datos estandarizados y k=1, obteniendo un puntaje F1 de 0.97. Este modelo obtuvo un rendimiento mejor a un modelo dummy, por lo que fue mejor que la aleatoriedad. Se concluye entonces que al utilizar un modelo clasificatorio de vecinos más cercanos siempre será mejor trabajar con datos estandarizados para controlar las diferencias en escala, que afectarán la calidad del modelo. A su vez, a medida que incrementa el número de k vecinos más cercanos, disminuyó la calidad del modelo, por lo que será mejor trabajar con valores bajos de k vecinos.\n",
    "3. Se estableció nuestra propia implementación de una regresión lineal, y al aplicarla en nuestro dataset original y en el dataset escalado, se pudo establecer que la estandarización de datos no influye en los resultados de las métricas RECM y R2, obteniendo valores similares en ambos modelos (RECM=0.34, R2=0.66). Sin embargo, si influyó en los valores de pesos obtenidos, siendo mayor para los datos escalados que para los datos no escalados. \n",
    "4. Sure Tomorrow buscaba proteger los datos personales de sus clientes, sin que esto afecte directamente la calidad del modelo de regresión lineal. Así que se construyó un algoritmo de ofuscación o enmascaramiento de datos, generando una nueva matriz ofuscada, resultado del producto entre la matriz original y una matriz aleatoria invertible. Posteriormente, se comprobó analíticamente a través del álgebra lineal y sus propiedades de matrices, que trabajar con datos ofuscados no afecta en las predicciones que realiza nuestro modelo, ya que al analizar los pesos de la matriz ofuscada, se pudo establecer que los valores predichos son exactamento iguales a las predicciones realizadas a partir de la matriz original. Finalmente, esto se comprobó computacionalmente, entrenando nuestro modelo con una matriz ofuscada, y obteniendo los mismos valores de RECM y R2 que nuestra matriz original. Concluyendo, que la ofuscación de datos es una alternativa efectiva para proteger la información personal de cada cliente, sin afectar el rendimiento final del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe 'x' para verificar. Luego presiona Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto\n",
    "- [x]  El código no tiene errores- [X]  Las celdas están ordenadas de acuerdo con la lógica y el orden de ejecución\n",
    "- [x]  Se ha realizado la tarea 1\n",
    "    - [x]  Está presente el procedimiento que puede devolver k clientes similares para un cliente determinado\n",
    "    - [x]  Se probó el procedimiento para las cuatro combinaciones propuestas    - [x]  Se respondieron las preguntas sobre la escala/distancia- [x]  Se ha realizado la tarea 2\n",
    "    - [x]  Se construyó y probó el modelo de clasificación aleatoria para todos los niveles de probabilidad    - [x]  Se construyó y probó el modelo de clasificación kNN tanto para los datos originales como para los escalados. Se calculó la métrica F1.- [x]  Se ha realizado la tarea 3\n",
    "    - [x]  Se implementó la solución de regresión lineal mediante operaciones matriciales    - [x]  Se calculó la RECM para la solución implementada- [x]  Se ha realizado la tarea 4\n",
    "    - [x]  Se ofuscaron los datos mediante una matriz aleatoria e invertible P    - [x]  Se recuperaron los datos ofuscados y se han mostrado algunos ejemplos    - [x]  Se proporcionó la prueba analítica de que la transformación no afecta a la RECM    - [x]  Se proporcionó la prueba computacional de que la transformación no afecta a la RECM- [x]  Se han sacado conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndices\n",
    "\n",
    "### Apéndice A: Escribir fórmulas en los cuadernos de Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes escribir fórmulas en tu Jupyter Notebook utilizando un lenguaje de marcado proporcionado por un sistema de publicación de alta calidad llamado $\\LaTeX$ (se pronuncia como \"Lah-tech\"). Las fórmulas se verán como las de los libros de texto.\n",
    "\n",
    "Para incorporar una fórmula a un texto, pon el signo de dólar (\\\\$) antes y después del texto de la fórmula, por ejemplo: $\\frac{1}{2} \\times \\frac{3}{2} = \\frac{3}{4}$ or $y = x^2, x \\ge 1$.\n",
    "\n",
    "Si una fórmula debe estar en el mismo párrafo, pon el doble signo de dólar (\\\\$\\\\$) antes y después del texto de la fórmula, por ejemplo:\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.\n",
    "$$\n",
    "\n",
    "El lenguaje de marcado de [LaTeX](https://es.wikipedia.org/wiki/LaTeX) es muy popular entre las personas que utilizan fórmulas en sus artículos, libros y textos. Puede resultar complicado, pero sus fundamentos son sencillos. Consulta esta [ficha de ayuda](http://tug.ctan.org/info/undergradmath/undergradmath.pdf) (materiales en inglés) de dos páginas para aprender a componer las fórmulas más comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apéndice B: Propiedades de las matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las matrices tienen muchas propiedades en cuanto al álgebra lineal. Aquí se enumeran algunas de ellas que pueden ayudarte a la hora de realizar la prueba analítica de este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>Distributividad</td><td>$A(B+C)=AB+AC$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>No conmutatividad</td><td>$AB \\neq BA$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Propiedad asociativa de la multiplicación</td><td>$(AB)C = A(BC)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Propiedad de identidad multiplicativa</td><td>$IA = AI = A$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td></td><td>$A^{-1}A = AA^{-1} = I$\n",
    "</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td></td><td>$(AB)^{-1} = B^{-1}A^{-1}$</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td>Reversibilidad de la transposición de un producto de matrices,</td><td>$(AB)^T = B^TA^T$</td>\n",
    "</tr>    \n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.07px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
